{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPP/jJQhP7uIzcDSc1tHT2g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcaraker76/hello-world/blob/main/A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUhhE74L1xBB"
      },
      "source": [
        "import numpy as np\r\n",
        "import urllib.request as ur\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "class KNNClassifier: #create the class\r\n",
        "    def __init__(self, k): \r\n",
        "      self.k = k\r\n",
        "        \r\n",
        "    def __repr__(self): #returns the number of neighbors\r\n",
        "      return str(self.k)\r\n",
        "    \r\n",
        "    def fit(self, X, y): #defines the fit function \r\n",
        "      self.x_train = X\r\n",
        "      self.y_train = y\r\n",
        "\r\n",
        "    def predict(self, X): #define the predict function\r\n",
        "      self.x_predict = X\r\n",
        "      prediction = [] #stores the predicted labels\r\n",
        "      k = self.k\r\n",
        "      for r in self.x_predict:  \r\n",
        "          distance = np.sum((self.x_train - r)**2, axis=1)  #distance between each input row and each new row\r\n",
        "          top_k = np.argsort(distance)[:k]\r\n",
        "          count = np.bincount(self.y_train[top_k].astype('int32')) #finds frequency of each label in top_k and converts it to an integer then flattens the array\r\n",
        "          prediction.append(np.argmax(count)) #add the label with the highest count to prediction list \r\n",
        "      return prediction\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "url = \"http://www.pjreddie.com/media/files/mnist_train.csv\" #load the url to maniuplate \r\n",
        "file = ur.urlopen(url)\r\n",
        "data = np.loadtxt(file, delimiter = ',')\r\n",
        "\r\n",
        "np.random.shuffle(data) #shuffle the data\r\n",
        "#Create the validation and training data and labels\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA6hY2tv4r6G"
      },
      "source": [
        "split_data_idx = int(data.shape[0]*0.8) #splitting the data 80%/20%\r\n",
        "\r\n",
        "val_data = data[split_data_idx: , 1:]\r\n",
        "train_data = data[:split_data_idx , 1:]\r\n",
        "val_label = data[split_data_idx:, 0]\r\n",
        "train_label = data[:split_data_idx, 0]\r\n",
        "\r\n",
        "# create a for loop for the values of 1 to 25\r\n",
        "acc = [] #list for the accuracy values \r\n",
        "knn = [KNNClassifier(k) for k in range(1 , 25)]\r\n",
        "for i in range(len(knn)): #feed using the fit method \r\n",
        "    knn[i].fit(train_data, train_label)\r\n",
        "    label_prediction = knn[i].predict(val_data)\r\n",
        "    acc_k = np.sum(np.array(label_prediction) == val_label) / val_data.shape[0] #calculate the accuracy \r\n",
        "    acc.append(acc_k)\r\n",
        "plt.plot(acc, knn)  \r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}